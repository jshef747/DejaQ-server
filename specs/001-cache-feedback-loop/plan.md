# Implementation Plan: Cache Feedback Loop

**Branch**: `001-cache-feedback-loop` | **Date**: 2026-02-19 | **Spec**: [spec.md](spec.md)
**Input**: Feature specification from `/specs/001-cache-feedback-loop/spec.md`

---

## Summary

Add a quality rating mechanism to DejaQ that lets API consumers submit thumbs-up / thumbs-down feedback after receiving a response. Ratings are stored as a `feedback_score` in ChromaDB entry metadata; the score drives three behaviors: trusted entries (high score) match queries more broadly, lowering LLM call frequency; low-scoring entries get flagged and removed from the cache; negative feedback on a fresh response cancels pending storage before it lands. The entire feature extends existing services (`MemoryService`, `cache_tasks`) without replacing them, and adds one new service (`FeedbackService`) and one new router (`feedback.py`).

---

## Technical Context

**Language/Version**: Python 3.13+
**Primary Dependencies**: FastAPI + Uvicorn, ChromaDB (PersistentClient), redis-py (already present as Celery dependency), Pydantic v2, Celery
**Storage**: ChromaDB (entry metadata), Redis (feedback event history, suppression flags)
**Testing**: pytest, `@pytest.mark.no_model` (all feedback tests are model-free)
**Target Platform**: macOS Apple Silicon (Metal), Linux (CUDA), CPU fallback
**Project Type**: Single FastAPI server
**Performance Goals**: Feedback submission completes in < 50ms (no inference involved); feedback history retrieval < 1s
**Constraints**: Score updates synchronous in the feedback endpoint (caller waits for updated score); no new ML models; no Celery tasks for score updates
**Scale/Scope**: Extends existing endpoints; no new infrastructure beyond Redis keys

---

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

| Principle | Status | Notes |
|-----------|--------|-------|
| I. Cost Optimization | âœ… PASS | Feature directly improves cache hit rate via trusted-entry relaxed matching |
| II. Non-Blocking UX | âœ… PASS | Score updates are in the feedback endpoint (caller expects them); chat response latency unaffected |
| III. Local-First Inference | âœ… PASS | No external API calls added |
| IV. Singleton Model Management | âœ… PASS | No new models; `FeedbackService` uses module-level singleton pattern |
| V. Separation of Tone/Semantics | âœ… PASS | Feature operates on cache metadata only; does not touch the generalize/adjust pipeline |
| No print() | âœ… PASS | All logging via `logging.getLogger("dejaq.services.feedback")` / `"dejaq.router.feedback"` |
| uv only | âœ… PASS | redis-py already a transitive Celery dependency; no new `pip install` |
| Pydantic v2 schemas | âœ… PASS | New schemas in `app/schemas/feedback.py` |
| Layer separation | âœ… PASS | router â†’ service â†’ (ChromaDB + Redis); service does not import router |
| Test markers | âœ… PASS | All tests `@pytest.mark.no_model` |
| No hardcoded secrets | âœ… PASS | All thresholds via `app/config.py` env vars |
| No per-request model loading | âœ… N/A | Feature has no models |

**Constitution check: PASS. No violations.**

---

## Over-Engineering Review

> The user asked to flag anything that feels over-engineered before finalizing.

The following were evaluated and rejected or accepted with justification:

| Item | Verdict | Reasoning |
|------|---------|-----------|
| Celery task for score updates | âŒ Rejected | Caller waits for updated score in response; deferring adds latency and complexity with zero benefit. Inline ChromaDB update is correct. |
| Redis for `feedback_score` storage | âŒ Rejected | Score lives in ChromaDB metadata alongside the entry it describes. Redis is only used for event history (append-only log) and suppression flags (TTL keys). No sync problem. |
| Separate FLAG and AUTO_DELETE thresholds | âœ… Accepted | Each serves a distinct purpose: FLAG stops serving; AUTO_DELETE reclaims space. Two config values is minimal. |
| FR-009 suppression (cancel pending storage) | âœ… Accepted with caveat | The implementation is minimal (one Redis SETEX + one GET check in the task). The race window is narrow but the feature is explicitly in scope. If team decides it's not worth it, this is the one item to cut without affecting any other behavior. |
| Separate `app/routers/feedback.py` | âœ… Accepted | Consistent with existing pattern; feedback endpoints don't belong in chat.py. |

---

## Project Structure

### Documentation (this feature)

```text
specs/001-cache-feedback-loop/
â”œâ”€â”€ plan.md              â† this file
â”œâ”€â”€ spec.md
â”œâ”€â”€ research.md
â”œâ”€â”€ data-model.md
â”œâ”€â”€ quickstart.md
â”œâ”€â”€ contracts/
â”‚   â”œâ”€â”€ feedback-api.yaml
â”‚   â””â”€â”€ chat-response-extension.yaml
â”œâ”€â”€ checklists/
â”‚   â””â”€â”€ requirements.md
â””â”€â”€ tasks.md             â† generated by /speckit.tasks (not yet created)
```

### Source Code Changes

```text
app/
â”œâ”€â”€ config.py                    MODIFY  add 5 threshold constants
â”œâ”€â”€ main.py                      MODIFY  register feedback router
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ chat.py                  MODIFY  add cache_entry_id to ChatResponse
â”‚   â””â”€â”€ feedback.py              CREATE  FeedbackRequest, FeedbackResponse, etc.
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ memory_chromaDB.py       MODIFY  dynamic threshold, flagged check, metadata CRUD
â”‚   â””â”€â”€ feedback_service.py      CREATE  FeedbackService (score updates, history, suppression)
â”œâ”€â”€ routers/
â”‚   â””â”€â”€ feedback.py              CREATE  POST/GET /cache/entries/{id}/feedback
â”œâ”€â”€ tasks/
â”‚   â””â”€â”€ cache_tasks.py           MODIFY  add suppression check before store_interaction

tests/
â”œâ”€â”€ test_feedback_service.py     CREATE  unit tests for FeedbackService
â””â”€â”€ test_memory_chromadb.py      MODIFY  add tests for dynamic threshold + flagged behavior

index.html                       MODIFY  add thumbs up/down feedback buttons on bot responses
```

**Structure Decision**: Single project (Option 1). All changes are additions/extensions to the existing `app/` tree. No new top-level directories needed.

---

## Implementation Phases

### Phase 1 â€” Config and Schema Extensions (no logic, no risk)

**Files**: `app/config.py`, `app/schemas/chat.py`, `app/schemas/feedback.py`

#### `app/config.py`

Add after existing constants:
```python
# Feedback loop thresholds
FEEDBACK_TRUSTED_THRESHOLD = int(os.getenv("DEJAQ_TRUSTED_THRESHOLD", "3"))
FEEDBACK_FLAG_THRESHOLD = int(os.getenv("DEJAQ_FLAG_THRESHOLD", "-3"))
FEEDBACK_AUTO_DELETE_THRESHOLD = int(os.getenv("DEJAQ_AUTO_DELETE_THRESHOLD", "-5"))
FEEDBACK_TRUSTED_SIMILARITY = float(os.getenv("DEJAQ_TRUSTED_SIMILARITY", "0.20"))
FEEDBACK_SUPPRESSION_TTL = int(os.getenv("DEJAQ_SUPPRESSION_TTL", "300"))
```

#### `app/schemas/chat.py`

Add one field to `ChatResponse`:
```python
cache_entry_id: Optional[str] = Field(None, description="ID of the cache entry for feedback submission")
```

#### `app/schemas/feedback.py` (new file)

```python
from pydantic import BaseModel
from datetime import datetime
from typing import Literal, Optional

class FeedbackRequest(BaseModel):
    value: Literal["positive", "negative"]
    conversation_id: Optional[str] = None

class FeedbackResponse(BaseModel):
    entry_id: str
    feedback_score: int
    flagged: bool
    deleted: bool
    status: str  # "ok" | "suppressed" | "not_found_suppressed"

class FeedbackEvent(BaseModel):
    direction: str
    timestamp: datetime

class FeedbackHistoryResponse(BaseModel):
    entry_id: str
    feedback_score: int
    flagged: bool
    events: list[FeedbackEvent]
```

---

### Phase 2 â€” MemoryService extensions

**File**: `app/services/memory_chromaDB.py`

#### 2a. Update `store_interaction` â€” initialize feedback metadata

Add `feedback_score` and `flagged` to the metadata dict in `store_interaction`:
```python
metadatas=[{
    "generalized_answer": generalized_answer,
    "original_query": original_query,
    "user_id": user_id,
    "stored_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
    "feedback_score": 0,    # â† new
    "flagged": 0,           # â† new (int; ChromaDB doesn't support bool natively)
}],
```

#### 2b. Update `check_cache` â€” return `(answer, entry_id)`, apply dynamic threshold, respect `flagged`

Current signature: `def check_cache(self, normalized_query: str) -> Optional[str]`
New signature: `def check_cache(self, normalized_query: str) -> Optional[tuple[str, str]]`

Changes:
1. Add `include=["documents", "metadatas", "distances"]` to the `.query()` call (metadatas already returned; make it explicit).
2. Before threshold comparison, get `feedback_score` and `flagged` from `results["metadatas"][0][0]`.
3. Short-circuit if `flagged == 1`: log and return `None`.
4. Select threshold: if `feedback_score >= FEEDBACK_TRUSTED_THRESHOLD` use `FEEDBACK_TRUSTED_SIMILARITY`, else `SIMILARITY_THRESHOLD`.
5. Return `(answer, entry_id)` on hit, `None` on miss.

The `entry_id` for a hit is the ChromaDB document ID from `results["ids"][0][0]`.

**Caller change in `chat.py`**: Both the HTTP and WebSocket handlers do:
```python
cache_result = memory.check_cache(clean_query)
if cache_result is not None:
    cached_answer, entry_id = cache_result
    # ... use entry_id in response
```

#### 2c. Add `get_entry_metadata(entry_id: str) -> Optional[dict]`

```python
def get_entry_metadata(self, entry_id: str) -> Optional[dict]:
    result = self._collection.get(ids=[entry_id], include=["metadatas"])
    if not result["ids"]:
        return None
    return result["metadatas"][0]
```

#### 2d. Add `update_entry_metadata(entry_id: str, metadata: dict) -> bool`

ChromaDB requires the full metadata dict on update. Caller must pass the complete dict:
```python
def update_entry_metadata(self, entry_id: str, metadata: dict) -> bool:
    try:
        self._collection.update(ids=[entry_id], metadatas=[metadata])
        logger.info("Updated metadata for entry %s", entry_id)
        return True
    except Exception:
        logger.error("Failed to update metadata for %s", entry_id, exc_info=True)
        return False
```

---

### Phase 3 â€” `chat.py` router updates

**File**: `app/routers/chat.py`

Two changes to expose `cache_entry_id` in responses:

#### 3a. Import doc_id helper

At the top of the file, add:
```python
import hashlib
```
(If already present in a future file state, ensure it's imported once.)

Add a module-level helper:
```python
def _compute_doc_id(clean_query: str) -> str:
    return hashlib.sha256(clean_query.encode()).hexdigest()[:16]
```

#### 3b. HTTP `/chat` endpoint

```python
# Cache check â€” unpack (answer, entry_id) or None
cache_result = memory.check_cache(clean_query)

if cache_result is not None:
    cached_answer, entry_id = cache_result
    # ... existing hit logic ...
    return ChatResponse(
        ...,
        cache_entry_id=entry_id,  # â† new
    )

# Cache miss â€” pre-compute entry_id
doc_id = _compute_doc_id(clean_query)

# ... existing miss logic ...

return ChatResponse(
    ...,
    cache_entry_id=doc_id if will_cache else None,  # â† new
)
```

#### 3c. WebSocket endpoint â€” same pattern

Same changes as above for the WebSocket handler. The response object is built before sending; add `cache_entry_id` in the same locations.

---

### Phase 4 â€” FeedbackService

**File**: `app/services/feedback_service.py` (new)

Module-level singleton:
```python
_feedback_service: Optional["FeedbackService"] = None

def get_feedback_service() -> "FeedbackService":
    global _feedback_service
    if _feedback_service is None:
        _feedback_service = FeedbackService()
    return _feedback_service
```

Class methods:

#### `submit_feedback(entry_id, value, conversation_id) -> FeedbackResponse`

```
1. Try get_entry_metadata(entry_id) from MemoryService
2. If not found:
   a. If value == "negative": set suppression flag (skip:{entry_id}) in Redis with TTL
      Return FeedbackResponse(status="suppressed", score=0, flagged=False, deleted=False)
   b. If value == "positive": no-op
      Return FeedbackResponse(status="not_found", ...)
3. Compute new_score = current feedback_score + (1 if positive else -1)
4. Determine new_flagged = new_score <= FEEDBACK_FLAG_THRESHOLD
5. If new_score <= FEEDBACK_AUTO_DELETE_THRESHOLD:
   a. memory.delete_entry(entry_id)
   b. Append event to Redis history
   c. Return FeedbackResponse(deleted=True, flagged=True, score=new_score, status="ok")
6. Update metadata: feedback_score=new_score, flagged=int(new_flagged), ... (full dict required)
7. Append event to Redis history: RPUSH feedback:{entry_id} JSON(direction, timestamp)
8. Return FeedbackResponse(score=new_score, flagged=new_flagged, deleted=False, status="ok")
```

#### `get_feedback_history(entry_id) -> FeedbackHistoryResponse`

```
1. get_entry_metadata(entry_id) â€” if None: raise HTTPException 404
2. Fetch events: LRANGE feedback:{entry_id} 0 -1 from Redis
3. Parse each JSON event into FeedbackEvent
4. Return FeedbackHistoryResponse(score=..., flagged=..., events=[...])
```

#### `_set_suppression_flag(doc_id: str) -> None`

```python
redis_client.setex(f"skip:{doc_id}", FEEDBACK_SUPPRESSION_TTL, "1")
```

#### Redis error handling

All Redis calls are wrapped in try/except `redis.exceptions.RedisError`. On error:
- Log warning: `logger.warning("Redis unavailable, skipping feedback history: %s", exc)`
- Continue without the history write; ChromaDB score update still proceeds.

---

### Phase 5 â€” FeedbackRouter

**File**: `app/routers/feedback.py` (new)

```python
import logging
from fastapi import APIRouter, HTTPException
from app.schemas.feedback import FeedbackRequest, FeedbackResponse, FeedbackHistoryResponse
from app.services.feedback_service import get_feedback_service

logger = logging.getLogger("dejaq.router.feedback")
router = APIRouter()

feedback_svc = get_feedback_service()

@router.post("/cache/entries/{entry_id}/feedback", response_model=FeedbackResponse)
async def submit_feedback(entry_id: str, request: FeedbackRequest):
    logger.info("POST /cache/entries/%s/feedback value=%s", entry_id, request.value)
    return feedback_svc.submit_feedback(entry_id, request.value, request.conversation_id)

@router.get("/cache/entries/{entry_id}/feedback", response_model=FeedbackHistoryResponse)
async def get_feedback_history(entry_id: str):
    logger.info("GET /cache/entries/%s/feedback", entry_id)
    return feedback_svc.get_feedback_history(entry_id)
```

#### Register in `app/main.py`

```python
from app.routers import chat, feedback
app.include_router(chat.router)
app.include_router(feedback.router)  # â† new
```

---

### Phase 6 â€” Suppression check in `cache_tasks.py`

**File**: `app/tasks/cache_tasks.py`

Add Redis suppression check at the start of `generalize_and_store_task`:

```python
import hashlib
import redis as redis_lib
from app.config import REDIS_URL

def _is_suppressed(clean_query: str) -> bool:
    doc_id = hashlib.sha256(clean_query.encode()).hexdigest()[:16]
    try:
        r = redis_lib.Redis.from_url(REDIS_URL, decode_responses=True)
        return r.exists(f"skip:{doc_id}") == 1
    except redis_lib.exceptions.RedisError:
        return False  # Redis unavailable: proceed with storage

@celery_app.task(...)
def generalize_and_store_task(self, clean_query, answer, original_query, user_id):
    if _is_suppressed(clean_query):
        logger.info("Storage suppressed for query '%s'", clean_query[:60])
        return {"status": "suppressed", "clean_query": clean_query}
    # ... existing logic ...
```

The same check applies to the in-process `_generalize_and_store` fallback in `chat.py`:

```python
def _generalize_and_store(clean_query, answer, original_query, user_id):
    if _is_suppressed(clean_query):
        logger.info("Storage suppressed (in-process) for query '%s'", clean_query[:60])
        return
    # ... existing logic ...
```

Note: `_is_suppressed` can be a shared utility. Consider placing it in `app/services/feedback_service.py` and importing it from both callers, or duplicating the two-liner given its simplicity.

---

### Phase 7 â€” Tests

**Files**: `tests/test_feedback_service.py` (new), `tests/test_memory_chromadb.py` (extended)

All tests: `@pytest.mark.no_model` â€” no ML models required.

#### `tests/test_feedback_service.py`

Use `tmp_path` fixture for MemoryService; mock Redis client.

```
class TestScoreMechanics:
  test_positive_increments_score
  test_negative_decrements_score
  test_score_starts_at_zero
  test_multiple_ratings_accumulate

class TestFlagging:
  test_score_below_flag_threshold_sets_flagged
  test_flagged_entry_not_served_by_check_cache
  test_score_below_auto_delete_threshold_deletes_entry

class TestSuppression:
  test_negative_feedback_on_missing_entry_sets_suppression_flag
  test_positive_feedback_on_missing_entry_is_noop
  test_suppression_flag_key_format

class TestFeedbackHistory:
  test_history_returns_events_in_order
  test_history_empty_for_no_feedback
  test_history_404_for_nonexistent_entry

class TestRedisUnavailable:
  test_score_update_succeeds_when_redis_down
  test_history_returns_empty_when_redis_down
```

#### `tests/test_memory_chromadb.py` (additions)

```
class TestDynamicThreshold:
  test_trusted_entry_matches_near_query
  test_neutral_entry_does_not_match_near_query
  test_flagged_entry_returns_miss
  test_check_cache_returns_entry_id_on_hit
  test_check_cache_returns_none_on_miss
```

---

### Phase 8 â€” UI: Feedback Buttons in `index.html`

**File**: `index.html` (project root)

Adds thumbs up / thumbs down buttons below each bot response. Buttons appear only when `cache_entry_id` is present in the WebSocket response. Clicking a button calls the feedback endpoint and locks the button pair to prevent double-submission.

#### 8a. New CSS styles

Add inside the existing `<style>` block, after `.badge-hard { ... }`:

```css
/* Feedback buttons */
.feedback-btns {
    display: flex;
    gap: 6px;
    margin-top: 6px;
}
.feedback-btn {
    background: none;
    border: 1px solid #334155;
    border-radius: 6px;
    color: #64748b;
    font-size: 0.9rem;
    padding: 3px 10px;
    cursor: pointer;
    transition: all 0.2s;
    line-height: 1.4;
}
.feedback-btn:hover:not(:disabled) {
    border-color: #94a3b8;
    color: #e0e0e0;
}
.feedback-btn.selected-positive {
    border-color: #22c55e;
    color: #22c55e;
    background: rgba(34, 197, 94, 0.1);
}
.feedback-btn.selected-negative {
    border-color: #ef4444;
    color: #ef4444;
    background: rgba(239, 68, 68, 0.1);
}
.feedback-btn:disabled {
    cursor: not-allowed;
    opacity: 0.5;
}
.feedback-score {
    font-size: 0.7rem;
    color: #64748b;
    align-self: center;
    font-family: monospace;
}
```

#### 8b. New JS function: `submitFeedback`

Add inside the `<script>` block, before the `connect()` call at the bottom:

```javascript
async function submitFeedback(entryId, value, thumbUpBtn, thumbDownBtn, scoreEl) {
    // Lock immediately to prevent double-submit
    thumbUpBtn.disabled = true;
    thumbDownBtn.disabled = true;

    try {
        const res = await fetch(API_BASE + "/cache/entries/" + entryId + "/feedback", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ value, conversation_id: conversationId || undefined })
        });

        if (res.ok) {
            const data = await res.json();
            if (value === "positive") {
                thumbUpBtn.classList.add("selected-positive");
            } else {
                thumbDownBtn.classList.add("selected-negative");
            }
            if (scoreEl) {
                const label = data.deleted ? "deleted" : (data.flagged ? "flagged" : "score: " + data.feedback_score);
                scoreEl.textContent = label;
            }
        } else {
            // Re-enable on failure so the user can retry
            thumbUpBtn.disabled = false;
            thumbDownBtn.disabled = false;
        }
    } catch (e) {
        thumbUpBtn.disabled = false;
        thumbDownBtn.disabled = false;
    }
}
```

#### 8c. Render feedback buttons in `ws.onmessage`

Inside the `ws.onmessage` handler, after the block that appends `badges` to `wrapper` (but before `messagesDiv.appendChild(wrapper)`), add:

```javascript
// Feedback buttons â€” only when a cache entry ID is available
if (data.cache_entry_id) {
    const feedbackRow = document.createElement("div");
    feedbackRow.className = "feedback-btns";

    const thumbUp = document.createElement("button");
    thumbUp.className = "feedback-btn";
    thumbUp.textContent = "ðŸ‘";
    thumbUp.title = "Helpful";

    const thumbDown = document.createElement("button");
    thumbDown.className = "feedback-btn";
    thumbDown.textContent = "ðŸ‘Ž";
    thumbDown.title = "Not helpful";

    const scoreEl = document.createElement("span");
    scoreEl.className = "feedback-score";

    thumbUp.onclick = () => submitFeedback(data.cache_entry_id, "positive", thumbUp, thumbDown, scoreEl);
    thumbDown.onclick = () => submitFeedback(data.cache_entry_id, "negative", thumbUp, thumbDown, scoreEl);

    feedbackRow.appendChild(thumbUp);
    feedbackRow.appendChild(thumbDown);
    feedbackRow.appendChild(scoreEl);
    wrapper.appendChild(feedbackRow);
}
```

#### 8d. Behavior notes

- **Placement**: Feedback buttons sit directly below the badge row (or below the bubble if no badges), left-aligned with the bot message.
- **Visibility**: Hidden for user messages; hidden for bot messages where `cache_entry_id` is null (e.g., filler responses the cache filter skipped).
- **Single-vote**: Both buttons disable immediately on click. On API failure they re-enable so the user can retry.
- **Score display**: After a successful vote, a small `score: N` label appears next to the buttons. If the entry was flagged or deleted, that status replaces the score.
- **Conversation switch**: Button state is preserved in `chatHistory` as serialized HTML. Event listeners are not restored after switching back to an old conversation â€” buttons appear in their last state (disabled if voted). This is acceptable for v1.

---

## Dependency Order

```
Phase 1 (config + schemas)
    â”‚
    â”œâ”€â–º Phase 2 (MemoryService extensions)
    â”‚       â””â”€â–º Phase 3 (chat.py updates â€” needs new check_cache signature)
    â”‚
    â”œâ”€â–º Phase 4 (FeedbackService â€” needs MemoryService methods from Phase 2)
    â”‚       â””â”€â–º Phase 5 (FeedbackRouter â€” needs FeedbackService)
    â”‚               â””â”€â–º Phase 5b (main.py registration)
    â”‚
    â”œâ”€â–º Phase 6 (cache_tasks.py suppression â€” can be done any time after Phase 1)
    â”‚
    â”œâ”€â–º Phase 7 (tests â€” after all implementation phases complete)
    â”‚
    â””â”€â–º Phase 8 (index.html UI â€” independent; can be done any time after Phase 5)
```

Phases 1 â†’ 2 â†’ 3 must be sequential (schema before service before router).
Phases 4, 5, 6 can proceed in parallel after Phase 2.
Phase 7 runs last.
Phase 8 (UI) is independent of all backend phases but requires the feedback endpoint (Phase 5) to be running to test end-to-end.

---

## Configuration Reference (new env vars)

| Variable | Default | Description |
|----------|---------|-------------|
| `DEJAQ_TRUSTED_THRESHOLD` | `3` | Min net-positive score for relaxed matching |
| `DEJAQ_FLAG_THRESHOLD` | `-3` | Score that marks entry as unreliable |
| `DEJAQ_AUTO_DELETE_THRESHOLD` | `-5` | Score that triggers deletion |
| `DEJAQ_TRUSTED_SIMILARITY` | `0.20` | Cosine distance ceiling for trusted entries |
| `DEJAQ_SUPPRESSION_TTL` | `300` | TTL in seconds for storage suppression flags |

---

## Artifacts

| File | Purpose |
|------|---------|
| [research.md](research.md) | All architectural decisions with rationale |
| [data-model.md](data-model.md) | Entity definitions, Redis key schemas, state transitions |
| [contracts/feedback-api.yaml](contracts/feedback-api.yaml) | OpenAPI spec for new endpoints |
| [contracts/chat-response-extension.yaml](contracts/chat-response-extension.yaml) | `cache_entry_id` field documentation |
| [quickstart.md](quickstart.md) | Usage guide with curl examples |